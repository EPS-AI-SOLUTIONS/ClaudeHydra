# ClaudeHydra Debug Logging Guide

## Poziomy Logowania

ClaudeHydra posiada wielopoziomowy system logowania oparty na kolorowych labelkach:

| Poziom | Emoji/Color | Opis | Kiedy U≈ºywaƒá |
|--------|-------------|------|--------------|
| **ERROR** | üî¥ `[ERROR]` | Krytyczne b≈Çƒôdy | Awarie, crashe, b≈Çƒôdy MCP |
| **WARN**  | üü° `[WARN]` | Ostrze≈ºenia | Deprecated features, slow queries |
| **INFO**  | üîµ `[INFO]` | Podstawowe info | Query completion, agent selection |
| **DEBUG** | üü£ `[DEBUG]` | Szczeg√≥≈Çy techniczne | MCP calls, Ollama params, agent routing |
| **TRACE** | ‚ö™ `[TRACE]` | Wszystko | Full request/response dumps |

---

## Uruchamianie z Logowaniem

### 1. **Standardowy Mode (INFO)**
```bash
pnpm start
# Pokazuje tylko podstawowe informacje:
# - Kt√≥ry agent zosta≈Ç wybrany
# - Czas wykonania query
# - Sukces/pora≈ºka
```

### 2. **Verbose Mode (DEBUG)**
```bash
pnpm start --verbose
# LUB
LOG_LEVEL=DEBUG pnpm start
```

**Output:**
```
[INFO]  ClaudeHydra CLI v3.0.0
[DEBUG] ü§ñ Selected: Jaskier - Auto-selected (score: 2.50)
        topScores: ["Jaskier:2.5", "Vesemir:1.0", "Geralt:0.5"]
[DEBUG] Processing query {
  agent: "Jaskier",
  model: "qwen3:4b",
  temperature: 0.8,
  streaming: false,
  promptLength: 456
}
[DEBUG] Ollama ‚Üí /api/generate {
  model: "qwen3:4b",
  tokens: 150,
  temperature: 0.8,
  penalties: { repeat: 1.5, frequency: 1.2 }
}
[TRACE] Ollama ‚Üê /api/generate {
  tokens_generated: 87,
  duration_ms: 1234,
  response_preview: "ClaudeHydra u≈ºywa 12 agent√≥w Witcher-themed..."
}
[INFO]  Query completed in 1234ms {
  responseLength: 245,
  cached: false
}
```

---

### 3. **Trace Mode (TRACE)**
```bash
pnpm start --trace
# LUB
LOG_LEVEL=TRACE pnpm start
```

**Output:** Jak DEBUG + pe≈Çne JSONy request/response z MCP i Ollama.

---

## Logowanie per Modu≈Ç

### **AgentRouter** (`[AgentRouter]`)
```
[DEBUG] ü§ñ Selected: Yennefer - Auto-selected (score: 3.00)
        topScores: ["Yennefer:3.0", "Dijkstra:2.5", "Regis:1.5"]
```

- **Pokazuje:** Kt√≥ry agent zosta≈Ç wybrany i dlaczego (top 3 scores)
- **Kiedy:** Przy ka≈ºdym query w trybie auto-select

---

### **QueryProcessor** (`[QueryProcessor]`)
```
[DEBUG] Processing query {
  agent: "Geralt",
  model: "qwen3:4b",
  temperature: 0.3,
  streaming: false,
  promptLength: 128
}
[INFO]  Query completed in 567ms { responseLength: 89, cached: false }
```

- **Pokazuje:** Parametry query + czas wykonania
- **Kiedy:** Przed i po ka≈ºdym wywo≈Çaniu AI

---

### **LlamaCppBridge** (`[LlamaCppBridge]`)
```
[DEBUG] Ollama ‚Üí /api/generate {
  model: "qwen3:4b",
  tokens: 150,
  temperature: 0.7,
  penalties: { repeat: 1.5, frequency: 1.2 }
}
[TRACE] Ollama ‚Üê /api/generate {
  tokens_generated: 102,
  duration_ms: 1456,
  response_preview: "Mam kilka pomysli dotyczƒÖcych swojego..."
}
```

- **Pokazuje:** Pe≈Çne parametry wysy≈Çane do Ollama + response stats
- **Kiedy:** Przy ka≈ºdym wywo≈Çaniu Ollama API

---

### **MCPClientManager** (`[MCPClientManager]`)
```
[DEBUG] MCP ‚Üí mcp__ollama__ollama_generate {
  params: { prompt: "...", model: "qwen3:4b", ... }
}
[TRACE] MCP ‚Üê mcp__ollama__ollama_generate {
  response: { content: "...", success: true }
}
```

- **Pokazuje:** Wszystkie wywo≈Çania MCP tools
- **Kiedy:** Przy ka≈ºdym request do MCP serwera

---

## Zmienne ≈örodowiskowe

| Zmienna | Opis | Przyk≈Çad |
|---------|------|----------|
| `LOG_LEVEL` | Poziom logowania | `LOG_LEVEL=DEBUG pnpm start` |
| `LOG_TIMESTAMPS` | W≈ÇƒÖcz timestampy | `LOG_TIMESTAMPS=1 pnpm start` |
| `FORCE_COLOR` | W≈ÇƒÖcz kolory | `FORCE_COLOR=3 pnpm start` |

---

## Kombinacje U≈ºyteczne

### **Debugowanie Repetycji**
```bash
LOG_LEVEL=TRACE pnpm start --verbose
# Poka≈ºe pe≈Çne parametry Ollama (repeat_penalty, frequency_penalty)
# + pe≈ÇnƒÖ odpowied≈∫ przed i po deduplication
```

### **Debugowanie Wyboru Agenta**
```bash
LOG_LEVEL=DEBUG pnpm start
# Poka≈ºe top 3 agent√≥w z scorami dla ka≈ºdego query
```

### **Debugowanie MCP Connection**
```bash
LOG_LEVEL=DEBUG pnpm start 2>&1 | grep MCP
# Filtruj tylko logi zwiƒÖzane z MCP
```

### **Performance Profiling**
```bash
LOG_TIMESTAMPS=1 LOG_LEVEL=DEBUG pnpm start
# Timestampy poka≈ºƒÖ dok≈Çadnie gdzie jest bottleneck
```

---

## Przyk≈Çadowy Output (--verbose)

```
[21:37:42.123] [UnifiedCLI] [INFO]  Verbose mode enabled (DEBUG level)
[21:37:42.456] [INFO]  ClaudeHydra CLI v3.0.0
[21:37:42.789] [INFO]  Mode: swarm

HYDRA> podaj sw√≥j pipeline z modelami ai

[21:37:45.012] [AgentRouter] [DEBUG] ü§ñ Selected: Jaskier - Auto-selected (score: 2.50) {
  topScores: [ 'Jaskier:2.5', 'Vesemir:1.0', 'Geralt:0.5' ]
}
[21:37:45.034] [QueryProcessor] [DEBUG] Processing query {
  agent: 'Jaskier',
  model: 'qwen3:4b',
  temperature: 0.8,
  streaming: false,
  promptLength: 456
}
[21:37:45.056] [LlamaCppBridge] [DEBUG] Ollama ‚Üí /api/generate {
  model: 'qwen3:4b',
  tokens: 150,
  temperature: 0.8,
  penalties: { repeat: 1.5, frequency: 1.2 }
}
[21:37:46.289] [LlamaCppBridge] [TRACE] Ollama ‚Üê /api/generate {
  tokens_generated: 87,
  duration_ms: 1233,
  response_preview: 'ClaudeHydra u≈ºywa lokalnie Ollama (qwen3:4b) + Anthropic API...'
}
[21:37:46.301] [QueryProcessor] [INFO]  Query completed in 1267ms {
  responseLength: 245,
  cached: false
}

ClaudeHydra u≈ºywa lokalnie Ollama (qwen3:4b) + Anthropic API dla chmury.
Pipeline: QueryProcessor ‚Üí AgentRouter ‚Üí LlamaCppBridge ‚Üí Ollama.

HYDRA>
```

---

## FAQ

**Q: Dlaczego nie widzƒô log√≥w MCP?**
A: Upewnij siƒô ≈ºe `LOG_LEVEL=DEBUG` lub `--verbose`. MCP logi sƒÖ na poziomie DEBUG.

**Q: Jak wy≈ÇƒÖczyƒá kolory?**
A: `FORCE_COLOR=0 pnpm start`

**Q: Jak zapisaƒá logi do pliku?**
A: `pnpm start --verbose 2>&1 | tee debug.log`

**Q: Timestampy sƒÖ w z≈Çej strefie czasowej?**
A: Logger u≈ºywa `toLocaleTimeString('pl-PL')` - zmie≈Ñ locale w `src/utils/logger.ts`

---

## Zg≈Çaszanie Bug√≥w

Przy zg≈Çaszaniu bug√≥w **zawsze do≈ÇƒÖcz**:
```bash
LOG_LEVEL=TRACE LOG_TIMESTAMPS=1 pnpm start > bug-report.log 2>&1
```

Output z `--trace` zawiera wszystkie potrzebne informacje dla deweloper√≥w.
