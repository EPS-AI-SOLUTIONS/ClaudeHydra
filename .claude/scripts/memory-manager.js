#!/usr/bin/env node
/**
 * HYDRA 10.6.1 - Memory Manager
 *
 * Automatyczne tworzenie i zarzÄ…dzanie Serena memories:
 * - Analiza codebase i generowanie memories
 * - Chat history tracking
 * - Context extraction
 * - Auto-update on changes
 * - Ollama integration for AI-powered memory processing
 */

const fs = require('fs');
const path = require('path');

// Lazy load ollama-handler to avoid circular deps
let ollamaHandler = null;
function getOllamaHandler() {
  if (!ollamaHandler) {
    try {
      ollamaHandler = require('./ollama-handler.js');
    } catch (e) {
      console.warn('Ollama handler not available:', e.message);
    }
  }
  return ollamaHandler;
}

const MEMORIES_DIR = path.join(__dirname, '..', '..', '.serena', 'memories');
const CHAT_HISTORY_FILE = path.join(MEMORIES_DIR, 'chat_history.json');
const CONTEXT_FILE = path.join(MEMORIES_DIR, 'current_context.md');

/**
 * Ensure memories directory exists
 */
function ensureMemoriesDir() {
  if (!fs.existsSync(MEMORIES_DIR)) {
    fs.mkdirSync(MEMORIES_DIR, { recursive: true });
  }
}

/**
 * Get all memory files
 */
function getMemories() {
  ensureMemoriesDir();
  const files = fs.readdirSync(MEMORIES_DIR).filter(f => f.endsWith('.md'));
  return files.map(f => ({
    name: f.replace('.md', ''),
    path: path.join(MEMORIES_DIR, f),
    content: fs.readFileSync(path.join(MEMORIES_DIR, f), 'utf-8'),
    modified: fs.statSync(path.join(MEMORIES_DIR, f)).mtime
  }));
}

/**
 * Get chat history
 */
function getChatHistory() {
  ensureMemoriesDir();
  if (!fs.existsSync(CHAT_HISTORY_FILE)) {
    return { sessions: [], lastUpdated: null };
  }
  return JSON.parse(fs.readFileSync(CHAT_HISTORY_FILE, 'utf-8'));
}

/**
 * Add chat entry to history
 */
function addChatEntry(entry) {
  const history = getChatHistory();
  const sessionId = entry.sessionId || `session_${Date.now()}`;

  let session = history.sessions.find(s => s.id === sessionId);
  if (!session) {
    session = {
      id: sessionId,
      started: new Date().toISOString(),
      entries: []
    };
    history.sessions.push(session);
  }

  session.entries.push({
    timestamp: new Date().toISOString(),
    role: entry.role,
    content: entry.content,
    model: entry.model || 'unknown',
    tokens: entry.tokens || 0
  });

  session.lastUpdated = new Date().toISOString();
  history.lastUpdated = new Date().toISOString();

  // Keep only last 50 sessions
  if (history.sessions.length > 50) {
    history.sessions = history.sessions.slice(-50);
  }

  fs.writeFileSync(CHAT_HISTORY_FILE, JSON.stringify(history, null, 2));
  return session;
}

/**
 * Create or update a memory file
 */
function saveMemory(name, content, metadata = {}) {
  ensureMemoriesDir();
  const filePath = path.join(MEMORIES_DIR, `${name}.md`);

  const header = `# ${name.replace(/_/g, ' ').replace(/\b\w/g, l => l.toUpperCase())}

> Auto-generated by HYDRA Memory System
> Last updated: ${new Date().toISOString()}
${metadata.description ? `> ${metadata.description}` : ''}

---

`;

  fs.writeFileSync(filePath, header + content);
  return filePath;
}

/**
 * Extract context from recent chat history
 */
function extractContext(maxEntries = 20) {
  const history = getChatHistory();
  const recentSessions = history.sessions.slice(-3);

  const context = {
    recentTopics: [],
    recentFiles: [],
    recentCommands: [],
    summary: ''
  };

  for (const session of recentSessions) {
    const entries = session.entries.slice(-maxEntries);
    for (const entry of entries) {
      // Extract topics (simple keyword extraction)
      const words = entry.content.toLowerCase().split(/\s+/);
      const keywords = words.filter(w =>
        w.length > 4 &&
        !['about', 'which', 'where', 'there', 'their', 'would', 'could', 'should'].includes(w)
      );
      context.recentTopics.push(...keywords.slice(0, 5));

      // Extract file paths
      const filePaths = entry.content.match(/[\w\/\-\.]+\.(ts|js|md|json|rs|py|tsx|jsx)/g) || [];
      context.recentFiles.push(...filePaths);

      // Extract commands
      const commands = entry.content.match(/\/\w+/g) || [];
      context.recentCommands.push(...commands);
    }
  }

  // Deduplicate and limit
  context.recentTopics = [...new Set(context.recentTopics)].slice(0, 20);
  context.recentFiles = [...new Set(context.recentFiles)].slice(0, 15);
  context.recentCommands = [...new Set(context.recentCommands)].slice(0, 10);

  return context;
}

/**
 * Generate context summary markdown
 */
function generateContextSummary() {
  const context = extractContext();
  const memories = getMemories();

  let summary = `# Current Context

## Recent Topics
${context.recentTopics.length ? context.recentTopics.map(t => `- ${t}`).join('\n') : '- No recent topics'}

## Recent Files
${context.recentFiles.length ? context.recentFiles.map(f => `- \`${f}\``).join('\n') : '- No recent files'}

## Recent Commands
${context.recentCommands.length ? context.recentCommands.map(c => `- \`${c}\``).join('\n') : '- No recent commands'}

## Available Memories
${memories.map(m => `- **${m.name}** (${new Date(m.modified).toLocaleDateString()})`).join('\n')}

---
*Generated: ${new Date().toISOString()}*
`;

  fs.writeFileSync(CONTEXT_FILE, summary);
  return summary;
}

/**
 * Auto-generate memory from codebase analysis
 */
async function analyzeAndGenerateMemory(type) {
  const projectRoot = path.join(__dirname, '..', '..');

  switch (type) {
    case 'codebase_structure': {
      const structure = [];

      function walkDir(dir, prefix = '') {
        const items = fs.readdirSync(dir);
        for (const item of items) {
          if (item.startsWith('.') && !item.startsWith('.claude') && !item.startsWith('.serena')) continue;
          if (item === 'node_modules' || item === 'target' || item === 'dist') continue;

          const fullPath = path.join(dir, item);
          const stat = fs.statSync(fullPath);

          if (stat.isDirectory()) {
            structure.push(`${prefix}ğŸ“ ${item}/`);
            walkDir(fullPath, prefix + '  ');
          } else {
            const icon = item.endsWith('.ts') || item.endsWith('.tsx') ? 'ğŸ“˜' :
                        item.endsWith('.js') ? 'ğŸ“™' :
                        item.endsWith('.rs') ? 'ğŸ¦€' :
                        item.endsWith('.md') ? 'ğŸ“' :
                        item.endsWith('.json') ? 'ğŸ“‹' : 'ğŸ“„';
            structure.push(`${prefix}${icon} ${item}`);
          }
        }
      }

      walkDir(projectRoot);
      saveMemory('codebase_structure', '```\n' + structure.slice(0, 100).join('\n') + '\n```');
      break;
    }

    case 'api_keys_status': {
      const envVars = [
        'ANTHROPIC_API_KEY',
        'GOOGLE_API_KEY',
        'GEMINI_API_KEY',
        'OPENAI_API_KEY',
        'XAI_API_KEY',
        'DEEPSEEK_API_KEY',
        'OLLAMA_HOST'
      ];

      const status = envVars.map(v => {
        const value = process.env[v];
        const hasKey = !!value;
        const masked = hasKey ? `${value.substring(0, 8)}...` : 'NOT SET';
        return `| ${v} | ${hasKey ? 'âœ…' : 'âŒ'} | ${masked} |`;
      });

      saveMemory('api_keys_status', `
| Variable | Status | Value |
|----------|--------|-------|
${status.join('\n')}

## Notes
- Keys are loaded from environment variables
- Some keys may be in \`.env\` file (not committed)
`);
      break;
    }

    case 'active_models': {
      try {
        const { loadAllProviders } = require('./model-loader.js');
        const providers = await loadAllProviders();

        const modelList = Object.entries(providers)
          .filter(([k]) => !k.startsWith('_'))
          .map(([name, data]) => {
            const status = data.available ? 'âœ…' : 'âŒ';
            const best = data.best || 'N/A';
            const count = data.models?.length || 0;
            return `| ${name} | ${status} | ${best} | ${count} |`;
          });

        saveMemory('active_models', `
| Provider | Available | Best Model | Total |
|----------|-----------|------------|-------|
${modelList.join('\n')}

## Model Selection
- Models are lazy-loaded on first use
- Cache TTL: 5 minutes
- Auto-selection based on task type
`);
      } catch (e) {
        console.error('Could not load models:', e.message);
      }
      break;
    }
  }
}

/**
 * List all memories with summaries
 */
function listMemories() {
  const memories = getMemories();

  console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘  ğŸ§  SERENA MEMORIES                                          â•‘');
  console.log('â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£');

  for (const memory of memories) {
    const lines = memory.content.split('\n').filter(l => l.trim()).slice(0, 3);
    const preview = lines[0]?.substring(0, 50) || 'Empty';
    console.log(`â•‘  ğŸ“ ${memory.name.padEnd(25)} ${new Date(memory.modified).toLocaleDateString().padEnd(12)} â•‘`);
  }

  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  return memories;
}

/**
 * Get memory content by name
 */
function getMemory(name) {
  const filePath = path.join(MEMORIES_DIR, `${name}.md`);
  if (!fs.existsSync(filePath)) {
    return null;
  }
  return fs.readFileSync(filePath, 'utf-8');
}

/**
 * Delete a memory
 */
function deleteMemory(name) {
  const filePath = path.join(MEMORIES_DIR, `${name}.md`);
  if (fs.existsSync(filePath)) {
    fs.unlinkSync(filePath);
    return true;
  }
  return false;
}

/**
 * Main CLI
 */
async function main() {
  const args = process.argv.slice(2);
  const command = args[0] || 'list';

  switch (command) {
    case 'list':
      listMemories();
      break;

    case 'get': {
      const name = args[1];
      if (!name) {
        console.log('Usage: memory-manager.js get <name>');
        process.exit(1);
      }
      const content = getMemory(name);
      if (content) {
        console.log(content);
      } else {
        console.log(`Memory "${name}" not found`);
      }
      break;
    }

    case 'save': {
      const name = args[1];
      const content = args.slice(2).join(' ');
      if (!name || !content) {
        console.log('Usage: memory-manager.js save <name> <content>');
        process.exit(1);
      }
      const filePath = saveMemory(name, content);
      console.log(`Memory saved: ${filePath}`);
      break;
    }

    case 'delete': {
      const name = args[1];
      if (!name) {
        console.log('Usage: memory-manager.js delete <name>');
        process.exit(1);
      }
      if (deleteMemory(name)) {
        console.log(`Memory "${name}" deleted`);
      } else {
        console.log(`Memory "${name}" not found`);
      }
      break;
    }

    case 'context':
      console.log(generateContextSummary());
      break;

    case 'update':
    case 'analyze':
      console.log('Analyzing codebase and updating memories...\n');
      await analyzeAndGenerateMemory('codebase_structure');
      await analyzeAndGenerateMemory('api_keys_status');
      await analyzeAndGenerateMemory('active_models');
      generateContextSummary();
      console.log('âœ… Memories updated');
      listMemories();
      break;

    case 'chat': {
      const role = args[1];
      const content = args.slice(2).join(' ');
      if (!role || !content) {
        console.log('Usage: memory-manager.js chat <role> <content>');
        process.exit(1);
      }
      addChatEntry({ role, content });
      console.log('Chat entry added');
      break;
    }

    case 'history': {
      const history = getChatHistory();
      console.log(JSON.stringify(history, null, 2));
      break;
    }

    default:
      console.log(`
HYDRA Memory Manager
====================

Commands:
  list              List all memories
  get <name>        Get memory content
  save <name> <...> Save new memory
  delete <name>     Delete memory
  context           Generate context summary
  update            Analyze codebase and update memories
  chat <role> <...> Add chat entry
  history           Show chat history
`);
  }
}

/**
 * AI-powered memory query using Ollama
 */
async function queryMemory(memoryName, question) {
  const ollama = getOllamaHandler();
  if (!ollama) {
    return { error: 'Ollama not available' };
  }

  const content = getMemory(memoryName);
  if (!content) {
    return { error: `Memory "${memoryName}" not found` };
  }

  return ollama.processMemory(content, 'query', { question });
}

/**
 * AI-powered memory summarization
 */
async function summarizeMemory(memoryName) {
  const ollama = getOllamaHandler();
  if (!ollama) {
    return { error: 'Ollama not available' };
  }

  const content = getMemory(memoryName);
  if (!content) {
    return { error: `Memory "${memoryName}" not found` };
  }

  return ollama.processMemory(content, 'summarize');
}

/**
 * AI-powered context analysis
 */
async function analyzeContext() {
  const ollama = getOllamaHandler();
  if (!ollama) {
    return { error: 'Ollama not available' };
  }

  const context = extractContext();
  const memories = getMemories();

  const contextSummary = `
Recent topics: ${context.recentTopics.join(', ') || 'none'}
Recent files: ${context.recentFiles.join(', ') || 'none'}
Recent commands: ${context.recentCommands.join(', ') || 'none'}
Available memories: ${memories.map(m => m.name).join(', ')}
  `.trim();

  return ollama.query(`Based on this context, what should the user focus on next?\n\n${contextSummary}`);
}

/**
 * AI-powered search across all memories
 */
async function searchMemories(query) {
  const ollama = getOllamaHandler();
  if (!ollama) {
    return { error: 'Ollama not available' };
  }

  const memories = getMemories();
  const allContent = memories.map(m =>
    `=== ${m.name} ===\n${m.content.substring(0, 1000)}`
  ).join('\n\n');

  return ollama.query(`Search these memories for: "${query}"\n\nMemories:\n${allContent}`);
}

/**
 * Auto-generate memory from content using AI
 */
async function generateMemoryFromContent(name, content, type = 'auto') {
  const ollama = getOllamaHandler();
  if (!ollama) {
    // Fallback to simple save
    return saveMemory(name, content);
  }

  const prompts = {
    auto: `Analyze this content and create a structured memory document with: 1) Summary, 2) Key points, 3) Technical details.\n\n${content}`,
    code: `Create a code documentation memory from this code: functions, classes, dependencies.\n\n${content}`,
    config: `Create a configuration reference memory from this config file.\n\n${content}`,
    notes: `Organize these notes into a structured memory document.\n\n${content}`
  };

  try {
    const result = await ollama.query(prompts[type] || prompts.auto);
    return saveMemory(name, result.response || content);
  } catch (e) {
    // Fallback
    return saveMemory(name, content);
  }
}

// Export for use as module
module.exports = {
  getMemories,
  getMemory,
  saveMemory,
  deleteMemory,
  getChatHistory,
  addChatEntry,
  extractContext,
  generateContextSummary,
  analyzeAndGenerateMemory,
  // AI-powered functions
  queryMemory,
  summarizeMemory,
  analyzeContext,
  searchMemories,
  generateMemoryFromContent
};

// Run if called directly
if (require.main === module) {
  main().catch(console.error);
}
